import numpy as np
def step_function(x, threshold):
    return 1 if x >= threshold else 0
class Perceptron:
    def __init__(self, input_size, weights, bias, learning_rate=0.1, epochs=100, threshold=0):
        self.weights = np.array([bias] + weights)
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.threshold = threshold
    def predict(self, inputs):
        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]
        return step_function(summation, self.threshold)
    def train(self, training_inputs, labels):
        for epoch in range(1, self.epochs + 1):
            errors = 0
            for inputs, label in zip(training_inputs, labels):
                prediction = self.predict(inputs)
                error = label - prediction
                if error != 0:
                    self.weights[1:] += self.learning_rate * error * inputs
                    self.weights[0] += self.learning_rate * error
                    errors += 1
            if errors == 0:
                return epoch
        return self.epochs
training_inputs = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])
labels = np.array([0, 0, 0, 1])
w1 = float(input("Enter initial weight w1: "))
w2 = float(input("Enter initial weight w2: "))
bias = float(input("Enter initial bias: "))
learning_rate = float(input("Enter learning rate: "))
threshold = float(input("Enter threshold for activation: "))
perceptron = Perceptron(
    input_size=2,
    weights=[w1, w2],
    bias=bias,
    learning_rate=learning_rate,
    epochs=100,
    threshold=threshold
)
converged_epoch = perceptron.train(training_inputs, labels)
print("\nFinal trained weights (bias first):", perceptron.weights)
print("Converged at epoch:", converged_epoch)
print("\nTesting AND gate:")
for inputs in training_inputs:
    print(f"{inputs} -> {perceptron.predict(inputs)}")
